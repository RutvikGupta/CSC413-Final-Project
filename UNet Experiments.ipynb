{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6huceXGyDq34",
        "outputId": "488a68e8-fe6b-4ad2-8bb8-ca4fc52e866c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (0.19.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (23.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (2.25.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (8.4.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (2023.3.21)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (4.65.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.12.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.53.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (67.6.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.8)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (0.0.4)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (6.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-image\n",
        "!pip install tqdm\n",
        "!pip install tensorflow\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2lab, lab2rgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV-jg3WNPEFn",
        "outputId": "3a972785-1e7f-48a7-e750-c7d68b02bea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-15 16:11:52--  http://images.cocodataset.org/zips/train2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.54.201, 52.216.34.209, 52.216.251.164, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.54.201|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19336861798 (18G) [application/zip]\n",
            "Saving to: ‘coco_train2017.zip’\n",
            "\n",
            "coco_train2017.zip   28%[====>               ]   5.17G  12.9MB/s    eta 17m 0s "
          ]
        }
      ],
      "source": [
        "!wget http://images.cocodataset.org/zips/train2017.zip -O coco_train2017.zip\n",
        "!wget http://images.cocodataset.org/zips/val2017.zip -O coco_val2017.zip\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip -O coco_ann2017.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNi9BYBLDtiy"
      },
      "outputs": [],
      "source": [
        "# Visualise the raw data\n",
        "from zipfile import ZipFile, BadZipFile\n",
        "import os\n",
        "def extract_zip_file(extract_path):\n",
        "    try:\n",
        "        with ZipFile(extract_path+\".zip\") as zfile:\n",
        "            zfile.extractall(\".\")\n",
        "        # remove zipfile\n",
        "        zfileTOremove=f\"{extract_path}\"+\".zip\"\n",
        "        if os.path.isfile(zfileTOremove):\n",
        "            os.remove(zfileTOremove)\n",
        "        else:\n",
        "            print(\"Error: %s file not found\" % zfileTOremove)    \n",
        "    except BadZipFile as e:\n",
        "        print(\"Error:\", e)\n",
        "\n",
        "extract_train_path = \"./coco_train2017\"\n",
        "extract_val_path = \"./coco_val2017\"\n",
        "extract_ann_path=\"./coco_ann2017\"\n",
        "extract_zip_file(extract_train_path)\n",
        "extract_zip_file(extract_val_path)\n",
        "extract_zip_file(extract_ann_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sLNSJA4F3la"
      },
      "outputs": [],
      "source": [
        "!mkdir data\n",
        "!cd data && git clone https://github.com/cocodataset/cocoapi\n",
        "!cd data/cocoapi/PythonAPI && make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MJz-4NBTGEMk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a38f1f-a4a8-40c6-b4cf-5431ed1aac67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.12.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import skimage.io as io\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print('TensorFlow version:', tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIyDhrHPGJ8d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "!pip install livelossplot --quiet\n",
        "from livelossplot.tf_keras import PlotLossesCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_vFDf7UGMsA"
      },
      "outputs": [],
      "source": [
        "COCO_ROOT = '/content'\n",
        "COCO_API_ROOT = './data/'\n",
        "import sys\n",
        "sys.path.insert(0, os.path.join(COCO_API_ROOT, 'cocoapi/PythonAPI'))\n",
        "from pycocotools.coco import COCO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Xsc0__8HadN"
      },
      "outputs": [],
      "source": [
        "class Dataset():\n",
        "\n",
        "    def crop_images(self, img, inp_size, random_crop=False):\n",
        "        shape = tf.shape(img)\n",
        "        pad = (\n",
        "            [0, tf.maximum(inp_size - shape[0], 0)],\n",
        "            [0, tf.maximum(inp_size - shape[1], 0)],\n",
        "            [0, 0],\n",
        "        )\n",
        "        img = tf.pad(img, pad)\n",
        "\n",
        "        if random_crop:\n",
        "            img = tf.image.random_crop(img, (inp_size, inp_size, shape[2]))\n",
        "        else: # central crop\n",
        "            shape = tf.shape(img)\n",
        "            ho = (shape[0] - inp_size) // 2\n",
        "            wo = (shape[1] - inp_size) // 2\n",
        "            img = img[ho:ho+inp_size, wo:wo+inp_size, :]\n",
        "\n",
        "        return img\n",
        "\n",
        "    def train_dataset(self, batch_size, epochs, inp_size):\n",
        "\n",
        "        def item_to_images(item):\n",
        "            random_crop = True\n",
        "            img_combined = tf.py_function(self.read_images, [item], tf.uint8)\n",
        "            img_combined = self.crop_images(img_combined, inp_size, random_crop)\n",
        "\n",
        "            img = tf.cast(img_combined[...,:3], tf.float32) / np.float32(255.)\n",
        "            mask_class = tf.cast(img_combined[...,3:4], tf.float32)\n",
        "            return img, mask_class\n",
        "\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(self.img_list)\n",
        "        dataset = dataset.shuffle(buffer_size=len(self.img_list))\n",
        "        dataset = dataset.map(item_to_images)\n",
        "        dataset = dataset.repeat(epochs)\n",
        "        dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "        return dataset\n",
        "\n",
        "    def val_dataset(self, batch_size, inp_size):\n",
        "\n",
        "        def item_to_images(item):\n",
        "            random_crop = False\n",
        "            img_combined = tf.py_function(self.read_images, [item], tf.uint8)\n",
        "            img_combined = self.crop_images(img_combined, inp_size, random_crop)\n",
        "\n",
        "            img = tf.cast(img_combined[...,:3], tf.float32) / np.float32(255.)\n",
        "            mask_class = tf.cast(img_combined[...,3:4], tf.float32)\n",
        "            return img, mask_class\n",
        "\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(self.img_list)\n",
        "        dataset = dataset.map(item_to_images)\n",
        "        dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "        return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOgqUPw2HcFY"
      },
      "outputs": [],
      "source": [
        "class COCO_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, sublist, percent=1):\n",
        "        ann_file_fpath = os.path.join(COCO_ROOT, 'annotations', 'instances_'+sublist+'2017.json')\n",
        "        self.coco = COCO(ann_file_fpath)\n",
        "        self.cat_ids = self.coco.getCatIds(catNms=['person'])\n",
        "        self.img_list = self.coco.getImgIds(catIds=self.cat_ids)\n",
        "        assert percent > 0 and percent <= 1\n",
        "        self.img_list = random.sample(self.img_list, int(len(self.img_list) * percent))\n",
        "\n",
        "    def read_images(self, img_id):\n",
        "        img_id = int(img_id.numpy())\n",
        "        img_data = self.coco.loadImgs(img_id)[0]\n",
        "        img_fname = '/'.join(img_data['coco_url'].split('/')[-2:])\n",
        "\n",
        "        img = io.imread(os.path.join(COCO_ROOT, img_fname))\n",
        "        if len(img.shape) == 2:\n",
        "            img = np.tile(img[..., None], (1, 1, 3))\n",
        "\n",
        "        ann_ids = self.coco.getAnnIds(imgIds=img_data['id'], catIds=self.cat_ids, iscrowd=None)\n",
        "        anns = self.coco.loadAnns(ann_ids)\n",
        "        mask_class = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
        "        for i in range(len(anns)):\n",
        "            mask_class += self.coco.annToMask(anns[i])\n",
        "        mask_class = (mask_class > 0).astype(np.uint8)\n",
        "\n",
        "        img_combined = np.concatenate([img, mask_class[..., None]], axis=2)\n",
        "\n",
        "        return img_combined"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ConvEncoder and ConvDecoder Blocks"
      ],
      "metadata": {
        "id": "v97wkVQbfE26"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7ihDn-GzYok"
      },
      "outputs": [],
      "source": [
        "def ConvEncoder(inputs, n_filters=32, dropout_prob=0.0, \n",
        "            weight_initializer='HeNormal', max_pooling=True):\n",
        "    c1 = tf.keras.layers.Conv2D(n_filters, 3, \n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  kernel_initializer=weight_initializer)(inputs)\n",
        "\n",
        "    c2 = tf.keras.layers.Conv2D(n_filters, 3,\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  kernel_initializer=weight_initializer)(c1)\n",
        "    \n",
        "    conv = tf.keras.layers.BatchNormalization()(c2, training=False)\n",
        "\n",
        "    if dropout_prob > 0.0:     \n",
        "        conv = tf.keras.layers.Dropout(dropout_prob)(conv)\n",
        "\n",
        "    if max_pooling:\n",
        "        next_layer = tf.keras.layers.MaxPooling2D(pool_size = (2,2))(conv)    \n",
        "    else:\n",
        "        next_layer = conv\n",
        "\n",
        "    skip_connection = conv\n",
        "    \n",
        "    return next_layer, skip_connection\n",
        "\n",
        "\n",
        "def ConvDecoder(prev_layer_input, skip_layer_input, n_filters=32, \n",
        "            weight_initializer='HeNormal'):\n",
        "    c1 = tf.keras.layers.Conv2DTranspose(n_filters, (3,3),\n",
        "                 strides=(2,2),\n",
        "                 padding='same')(prev_layer_input)\n",
        "\n",
        "    c2 = tf.keras.layers.Conv2D(n_filters, 3,\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer=weight_initializer)(tf.keras.layers.concatenate([c1, \n",
        "                                                            skip_layer_input], \n",
        "                                                            axis=3))\n",
        "\n",
        "    return tf.keras.layers.Conv2D(n_filters, 3,\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer=weight_initializer)(c2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UNetSimple Architecture"
      ],
      "metadata": {
        "id": "Av3pZQfpfgWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def UNetSimple(image_size=224, n_filters=32, weights='HeNormal', \n",
        "               dropout_prob=0.2):\n",
        "    inputs = tf.keras.layers.Input((image_size, image_size, 3))\n",
        "    e1 = ConvEncoder(inputs, n_filters, dropout_prob=0.0, \n",
        "                 weight_initializer=weights, max_pooling=True)\n",
        "    e2 = ConvEncoder(e1[0],n_filters*2, dropout_prob=0.0, \n",
        "                 weight_initializer=weights, max_pooling=True)\n",
        "    e3 = ConvEncoder(e2[0], n_filters*4, dropout_prob=dropout_prob, \n",
        "                 weight_initializer=weights, max_pooling=False)\n",
        "    \n",
        "    d4 = ConvDecoder(e3[0], e2[1],  n_filters * 2, weight_initializer=weights)\n",
        "    d5 = ConvDecoder(d4, e1[1],  n_filters * 1, weight_initializer=weights)\n",
        "\n",
        "    conv1 = tf.keras.layers.Conv2D(n_filters,\n",
        "                 3,\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer=weights)(d5)\n",
        "\n",
        "    conv2 = tf.keras.layers.Conv2D(1, (3, 3), padding='same', \n",
        "                                   activation='sigmoid')(conv1)\n",
        "    \n",
        "    model = tf.keras.Model(inputs=inputs, outputs=conv2)\n",
        "\n",
        "    return model\n",
        "UNetSimple().summary()"
      ],
      "metadata": {
        "id": "E_MWxxp5lREl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UNetDense Architecture"
      ],
      "metadata": {
        "id": "BUHgRiMbfkQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def UNetDense(image_size=224, n_filters=32, weights='HeNormal', \n",
        "               dropout_prob=0.3):\n",
        "    inputs = tf.keras.layers.Input((image_size, image_size, 3))\n",
        "    e1 = ConvEncoder(inputs, n_filters, dropout_prob=0.0, \n",
        "                 weight_initializer=weights, max_pooling=True)\n",
        "    e2 = ConvEncoder(e1[0],n_filters*2, dropout_prob=0.0, \n",
        "                 weight_initializer=weights, max_pooling=True)\n",
        "    e3 = ConvEncoder(e2[0], n_filters*4, dropout_prob=0.0, \n",
        "                 weight_initializer=weights, max_pooling=True)\n",
        "    e4 = ConvEncoder(e3[0], n_filters*8, dropout_prob=dropout_prob, \n",
        "                 weight_initializer=weights, max_pooling=True)\n",
        "    e5 = ConvEncoder(e4[0], n_filters*16, dropout_prob=dropout_prob, \n",
        "                 weight_initializer=weights, max_pooling=False)\n",
        "    \n",
        "    d6 = ConvDecoder(e5[0], e4[1],  n_filters * 8, weight_initializer=weights)\n",
        "    d7 = ConvDecoder(d6, e3[1],  n_filters * 2, weight_initializer=weights)\n",
        "    d8 = ConvDecoder(d7, e2[1],  n_filters * 2, weight_initializer=weights)\n",
        "    d9 = ConvDecoder(d8, e1[1],  n_filters, weight_initializer=weights)\n",
        "\n",
        "    conv10 = tf.keras.layers.Conv2D(n_filters,\n",
        "                 3,\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer=weights)(d9)\n",
        "\n",
        "    conv11 = tf.keras.layers.Conv2D(1, (3, 3), padding='same', \n",
        "                                   activation='sigmoid')(conv10)\n",
        "    \n",
        "    model = tf.keras.Model(inputs=inputs, outputs=conv11)\n",
        "\n",
        "    return model\n",
        "UNetDense().summary()"
      ],
      "metadata": {
        "id": "KGmBhmEhg3uQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# UNetSuperDense Architecture"
      ],
      "metadata": {
        "id": "8VKh6RTnfmOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def UNetSuperDense(image_size=256, n_filters=32, weights='HeNormal', \n",
        "               dropout_prob=0.3):\n",
        "    inputs = tf.keras.layers.Input((image_size, image_size, 3))\n",
        "    e1 = ConvEncoder(inputs, n_filters, dropout_prob=0.0, \n",
        "                 weight_initializer=weights, max_pooling=True)\n",
        "    e2 = ConvEncoder(e1[0],n_filters*2, dropout_prob=0.0, \n",
        "                 weight_initializer=weights, max_pooling=True)\n",
        "    e3 = ConvEncoder(e2[0], n_filters*4, dropout_prob=0.0, \n",
        "                 weight_initializer=weights, max_pooling=True)\n",
        "    e4 = ConvEncoder(e3[0], n_filters*8, dropout_prob=dropout_prob, \n",
        "                 weight_initializer=weights, max_pooling=True)\n",
        "    e5 = ConvEncoder(e4[0], n_filters*16, dropout_prob=dropout_prob, \n",
        "                 weight_initializer=weights, max_pooling=True)\n",
        "    e6 = ConvEncoder(e5[0], n_filters*32, dropout_prob=dropout_prob, \n",
        "                 weight_initializer=weights, max_pooling=True)\n",
        "    e7 = ConvEncoder(e6[0], n_filters*64, dropout_prob=dropout_prob, \n",
        "                 weight_initializer=weights, max_pooling=True)\n",
        "    e8 = ConvEncoder(e7[0], n_filters*128, dropout_prob=dropout_prob, \n",
        "                 weight_initializer=weights, max_pooling=False)\n",
        "    \n",
        "    d9 = ConvDecoder(e8[0], e7[1],  n_filters * 64, weight_initializer=weights)\n",
        "    d10 = ConvDecoder(d9, e6[1],  n_filters * 32, weight_initializer=weights)\n",
        "    d11 = ConvDecoder(d10, e5[1],  n_filters * 16, weight_initializer=weights)\n",
        "    d12 = ConvDecoder(d11, e4[1],  n_filters * 8, weight_initializer=weights)\n",
        "    d13 = ConvDecoder(d12, e3[1],  n_filters * 4, weight_initializer=weights)\n",
        "    d14 = ConvDecoder(d13, e2[1],  n_filters * 2, weight_initializer=weights)\n",
        "    d15 = ConvDecoder(d14, e1[1],  n_filters, weight_initializer=weights)\n",
        "\n",
        "    conv1 = tf.keras.layers.Conv2D(n_filters,\n",
        "                 3,\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer=weights)(d15)\n",
        "\n",
        "    conv2 = tf.keras.layers.Conv2D(1, (3, 3), padding='same', \n",
        "                                   activation='sigmoid')(conv1)\n",
        "    \n",
        "    model = tf.keras.Model(inputs=inputs, outputs=conv2)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "UNetSuperDense().summary()"
      ],
      "metadata": {
        "id": "BltTotEy1HsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaae2cb9-ed10-42a3-d0cf-d21339143eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 256, 256, 32  896         ['input_5[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 256, 256, 32  9248        ['conv2d_86[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 256, 256, 32  128        ['conv2d_87[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_22 (MaxPooling2D  (None, 128, 128, 32  0          ['batch_normalization_25[0][0]'] \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 128, 128, 64  18496       ['max_pooling2d_22[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 128, 128, 64  36928       ['conv2d_88[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 128, 128, 64  256        ['conv2d_89[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_23 (MaxPooling2D  (None, 64, 64, 64)  0           ['batch_normalization_26[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 64, 64, 128)  73856       ['max_pooling2d_23[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 64, 64, 128)  147584      ['conv2d_90[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 64, 64, 128)  512        ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " max_pooling2d_24 (MaxPooling2D  (None, 32, 32, 128)  0          ['batch_normalization_27[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 32, 32, 256)  295168      ['max_pooling2d_24[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 32, 32, 256)  590080      ['conv2d_92[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 32, 32, 256)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_25 (MaxPooling2D  (None, 16, 16, 256)  0          ['dropout_14[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 16, 16, 512)  1180160     ['max_pooling2d_25[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 16, 16, 512)  2359808     ['conv2d_94[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_95[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, 16, 16, 512)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_26 (MaxPooling2D  (None, 8, 8, 512)   0           ['dropout_15[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 8, 8, 1024)   4719616     ['max_pooling2d_26[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 8, 8, 1024)   9438208     ['conv2d_96[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 8, 8, 1024)  4096        ['conv2d_97[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)           (None, 8, 8, 1024)   0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_27 (MaxPooling2D  (None, 4, 4, 1024)  0           ['dropout_16[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 4, 4, 2048)   18876416    ['max_pooling2d_27[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 4, 4, 2048)   37750784    ['conv2d_98[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 4, 4, 2048)  8192        ['conv2d_99[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)           (None, 4, 4, 2048)   0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_28 (MaxPooling2D  (None, 2, 2, 2048)  0           ['dropout_17[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 2, 2, 4096)   75501568    ['max_pooling2d_28[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 2, 2, 4096)   150999040   ['conv2d_100[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 2, 2, 4096)  16384       ['conv2d_101[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)           (None, 2, 2, 4096)   0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_14 (Conv2DTra  (None, 4, 4, 2048)  75499520    ['dropout_18[0][0]']             \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 4, 4, 4096)   0           ['conv2d_transpose_14[0][0]',    \n",
            "                                                                  'dropout_17[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 4, 4, 2048)   75499520    ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 4, 4, 2048)   37750784    ['conv2d_102[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_transpose_15 (Conv2DTra  (None, 8, 8, 1024)  18875392    ['conv2d_103[0][0]']             \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 8, 8, 2048)   0           ['conv2d_transpose_15[0][0]',    \n",
            "                                                                  'dropout_16[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 8, 8, 1024)   18875392    ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 8, 8, 1024)   9438208     ['conv2d_104[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_transpose_16 (Conv2DTra  (None, 16, 16, 512)  4719104    ['conv2d_105[0][0]']             \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 16, 16, 1024  0           ['conv2d_transpose_16[0][0]',    \n",
            "                                )                                 'dropout_15[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 16, 16, 512)  4719104     ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 16, 16, 512)  2359808     ['conv2d_106[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_transpose_17 (Conv2DTra  (None, 32, 32, 256)  1179904    ['conv2d_107[0][0]']             \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 32, 32, 512)  0           ['conv2d_transpose_17[0][0]',    \n",
            "                                                                  'dropout_14[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 32, 32, 256)  1179904     ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 32, 32, 256)  590080      ['conv2d_108[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_transpose_18 (Conv2DTra  (None, 64, 64, 128)  295040     ['conv2d_109[0][0]']             \n",
            " nspose)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 64, 64, 256)  0           ['conv2d_transpose_18[0][0]',    \n",
            "                                                                  'batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 64, 64, 128)  295040      ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 64, 64, 128)  147584      ['conv2d_110[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_transpose_19 (Conv2DTra  (None, 128, 128, 64  73792      ['conv2d_111[0][0]']             \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 128, 128, 12  0           ['conv2d_transpose_19[0][0]',    \n",
            "                                8)                                'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, 128, 128, 64  73792       ['concatenate_7[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, 128, 128, 64  36928       ['conv2d_112[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose_20 (Conv2DTra  (None, 256, 256, 32  18464      ['conv2d_113[0][0]']             \n",
            " nspose)                        )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 256, 256, 64  0           ['conv2d_transpose_20[0][0]',    \n",
            "                                )                                 'batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (None, 256, 256, 32  18464       ['concatenate_8[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (None, 256, 256, 32  9248        ['conv2d_114[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (None, 256, 256, 32  9248        ['conv2d_115[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_117 (Conv2D)            (None, 256, 256, 1)  289         ['conv2d_116[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 553,695,105\n",
            "Trainable params: 553,678,785\n",
            "Non-trainable params: 16,320\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Architecture"
      ],
      "metadata": {
        "id": "fD0iVPqngYiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CNNencoder(inputs, n_filters=32, dropout_prob=0.0, \n",
        "            weight_initializer='HeNormal', max_pooling=True):\n",
        "    c1 = tf.keras.layers.Conv2D(n_filters, 3, \n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  kernel_initializer=weight_initializer)(inputs)\n",
        "\n",
        "    c2 = tf.keras.layers.Conv2D(n_filters, 3,\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  kernel_initializer=weight_initializer)(c1)\n",
        "    \n",
        "    conv = tf.keras.layers.BatchNormalization()(c2, training=False)\n",
        "\n",
        "    if dropout_prob > 0.0:     \n",
        "        conv = tf.keras.layers.Dropout(dropout_prob)(conv)\n",
        "\n",
        "    if max_pooling:\n",
        "        next_layer = tf.keras.layers.MaxPooling2D(pool_size = (2,2))(conv)    \n",
        "    else:\n",
        "        next_layer = conv\n",
        "    \n",
        "    return next_layer\n",
        "\n",
        "\n",
        "def CNNdecoder(prev_layer_input, n_filters=32, \n",
        "            weight_initializer='HeNormal'):\n",
        "    c1 = tf.keras.layers.Conv2DTranspose(n_filters, (3,3),\n",
        "                 strides=(2,2),\n",
        "                 padding='same')(prev_layer_input)\n",
        "\n",
        "    c2 = tf.keras.layers.Conv2D(n_filters, 3,\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer=weight_initializer)(c1)\n",
        "\n",
        "    return tf.keras.layers.Conv2D(n_filters, 3,\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer=weight_initializer)(c2)\n",
        "\n",
        "def CNNSuperDense(image_size=256, n_filters=32, weights='HeNormal', \n",
        "               dropout_prob=0.3):\n",
        "    inputs = tf.keras.layers.Input((image_size, image_size, 3))\n",
        "    e1 = CNNencoder(inputs, n_filters, dropout_prob=0.0, \n",
        "                 weight_initializer=weights, max_pooling=True)\n",
        "    e2 = CNNencoder(e1,n_filters*2, dropout_prob=0.0, \n",
        "                 weight_initializer=weights, max_pooling=True)\n",
        "    e3 = CNNencoder(e2, n_filters*4, dropout_prob=0.0, \n",
        "                 weight_initializer=weights, max_pooling=True)\n",
        "    e4 = CNNencoder(e3, n_filters*8, dropout_prob=dropout_prob, \n",
        "                 weight_initializer=weights, max_pooling=True)\n",
        "    e5 = CNNencoder(e4, n_filters*16, dropout_prob=dropout_prob, \n",
        "                 weight_initializer=weights, max_pooling=True)\n",
        "    e6 = CNNencoder(e5, n_filters*32, dropout_prob=dropout_prob, \n",
        "                 weight_initializer=weights, max_pooling=True)\n",
        "    e7 = CNNencoder(e6, n_filters*64, dropout_prob=dropout_prob, \n",
        "                 weight_initializer=weights, max_pooling=False)\n",
        "    \n",
        "    d8 = CNNdecoder(e7,  n_filters * 32, weight_initializer=weights)\n",
        "    d9 = CNNdecoder(d8,  n_filters * 16, weight_initializer=weights)\n",
        "    d10 = CNNdecoder(d9,  n_filters * 8, weight_initializer=weights)\n",
        "    d11 = CNNdecoder(d10,  n_filters * 4, weight_initializer=weights)\n",
        "    d12 = CNNdecoder(d11,  n_filters * 2, weight_initializer=weights)\n",
        "    d13 = CNNdecoder(d12,  n_filters, weight_initializer=weights)\n",
        "\n",
        "    conv1 = tf.keras.layers.Conv2D(n_filters,\n",
        "                 3,\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer=weights)(d13)\n",
        "\n",
        "    conv2 = tf.keras.layers.Conv2D(1, (3, 3), padding='same', \n",
        "                                   activation='sigmoid')(conv1)\n",
        "    \n",
        "    model = tf.keras.Model(inputs=inputs, outputs=conv2)\n",
        "\n",
        "    return model\n",
        "CNNSuperDense().summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXwtDt6Sev7b",
        "outputId": "7ba18090-e8c3-4cb9-bb70-342d5b40cb2c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 256, 256, 32)      896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 256, 256, 32)      9248      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256, 256, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 128, 128, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 128, 128, 64)      18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 128, 128, 64)      36928     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 128, 128, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 64, 64, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 64, 64, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 32, 32, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 32, 32, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 16, 16, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 16, 16, 512)      2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16, 16, 512)       0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 8, 8, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 8, 8, 1024)        4719616   \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 1024)        9438208   \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 8, 1024)       4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 8, 8, 1024)        0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 4, 4, 1024)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 4, 4, 2048)        18876416  \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 4, 4, 2048)        37750784  \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 4, 4, 2048)       8192      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4, 4, 2048)        0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 8, 8, 1024)       18875392  \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 8, 8, 1024)        9438208   \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 8, 8, 1024)        9438208   \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 512)      4719104   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 256)      1179904   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 32, 32, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 32, 32, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 64, 64, 128)      295040    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 64, 64, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 64, 64, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 128, 128, 64)     73792     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 128, 128, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 128, 128, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 256, 256, 32)     18464     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 256, 256, 32)      9248      \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 256, 256, 32)      9248      \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 256, 256, 32)      9248      \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 256, 256, 1)       289       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 125,848,449\n",
            "Trainable params: 125,840,321\n",
            "Non-trainable params: 8,128\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Dataset\n",
        "COCO_dataset_train = COCO_Dataset('train', 1.0)\n",
        "COCO_dataset_val = COCO_Dataset('val', 1.0)"
      ],
      "metadata": {
        "id": "eKyfnE5r7vWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beaa1c11-4fe0-45db-d543-ee8e8b77d0aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=35.19s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.56s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3xNMtYWIvyD"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 40\n",
        "IMAGE_SIZE = 256\n",
        "EPOCHS = 40\n",
        "\n",
        "train_ds = COCO_dataset_train.train_dataset(batch_size=BATCH_SIZE, epochs=EPOCHS, inp_size=IMAGE_SIZE)\n",
        "val_ds = COCO_dataset_val.val_dataset(batch_size=BATCH_SIZE, inp_size=IMAGE_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXQX3cyRI-hz"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEQDtyUZVEXM"
      },
      "outputs": [],
      "source": [
        "path = Path(\"model_1\")\n",
        "path.mkdir(exist_ok=True, parents=True) # folder created in google drive\n",
        "assert path.exists()\n",
        "# cpt_filename = \"checkpoint-{epoch:02d}-{val_loss:.2f}-{val_accuracy:.4f}.hdf5\"\n",
        "cpt_filename = \"best1.hdf5\"\n",
        "cpt_path =str(path / cpt_filename)\n",
        "\n",
        "# UNetSimple Model Training\n",
        "model = UNetSimple(image_size=IMAGE_SIZE)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(cpt_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "\n",
        "hist = model.fit(\n",
        "    train_ds, \n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=50,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[PlotLossesCallback(), checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = Path(\"model_2\")\n",
        "path.mkdir(exist_ok=True, parents=True) # folder created in google drive\n",
        "assert path.exists()\n",
        "cpt_filename = \"best2.hdf5\"\n",
        "cpt_path =str(path / cpt_filename)\n",
        "\n",
        "# UNetDense Model Training\n",
        "model = UNetDense(image_size=IMAGE_SIZE)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(cpt_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "optimizer = tf.keras.optimizers.Adam(0.0002)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "\n",
        "hist = model.fit(\n",
        "    train_ds, \n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=50,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[PlotLossesCallback(), checkpoint])"
      ],
      "metadata": {
        "id": "Y37pGTRrl1Du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = Path(\"model_3\")\n",
        "path.mkdir(exist_ok=True, parents=True) # folder created in google drive\n",
        "assert path.exists()\n",
        "cpt_filename = \"best3.hdf5\"\n",
        "cpt_path =str(path / cpt_filename)\n",
        "\n",
        "# UNetSuperDense Model Training\n",
        "model = UNetSuperDense(image_size=IMAGE_SIZE)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(cpt_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "optimizer = tf.keras.optimizers.Adam(0.00005)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "\n",
        "hist = model.fit(\n",
        "    train_ds, \n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=50,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[PlotLossesCallback(), checkpoint]\n",
        "    )"
      ],
      "metadata": {
        "id": "ToMf80071sL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = Path(\"model_4\")\n",
        "path.mkdir(exist_ok=True, parents=True) # folder created in google drive\n",
        "assert path.exists()\n",
        "cpt_filename = \"best4.hdf5\"\n",
        "cpt_path =str(path / cpt_filename)\n",
        "\n",
        "# CNNSuperDense Model Training\n",
        "model = CNNSuperDense(image_size=IMAGE_SIZE)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(cpt_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
        "\n",
        "hist = model.fit(\n",
        "    train_ds, \n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=50,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[PlotLossesCallback(), checkpoint]\n",
        "    )"
      ],
      "metadata": {
        "id": "II8bxU7xiaJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vy8Jn50_KZ07"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "########## Model Results ##########\n",
        "\n",
        "def draw_sub_image(i, sample, mask):\n",
        "    plt.subplot(4,4, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    # print(sample.shape, mask.shape)\n",
        "    mask = (mask[..., 0] > 0.2).astype(np.float32)\n",
        "    mask_clr = plt.get_cmap('viridis')(mask)[..., :3]\n",
        "    plt.imshow(sample*0.5 + mask_clr*0.5)\n",
        "    title_object = plt.title(\"Predicted\" if i % 2 else \"Real\")\n",
        "    _ = plt.setp(title_object, color=\"b\")\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "imgs, masks = next(train_ds.as_numpy_iterator())\n",
        "# imgs, masks = next(val_ds.as_numpy_iterator())\n",
        "\n",
        "for i, sample, mask in zip(range(imgs.shape[0]), imgs, masks):\n",
        "    pred_mask = model.predict(sample[None, ...])\n",
        "    if i > 7:\n",
        "        break\n",
        "    draw_sub_image(2*i, sample, mask)\n",
        "    draw_sub_image(2*i + 1, sample, pred_mask[0, ...])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}